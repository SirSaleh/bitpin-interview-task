# استراتژی من برای کنترل اسپم


## توضیح منطق استراتژی


در ابتدا خواستم که ارزیابی آرای کاربران جدید را محدود کنم، اما این روش به‌نظرم نیومد. چون به شکل طبیعی در زمان‌های مشخصی ممکنه به خاطر موجود شدن کالا در یک مارکت کاربران واقعی اون کالا در جمع جدید کاربران حضور پیدا کنن و بخوان امتیازدهی داشته باشن.

با کمی فکر و بررسی استراتژی‌های ممکن یک ایده ساده آماری به‌ذهنم رسید. اون هم استفاده از میانگینِ میانگین‌های دوره‌ای به جای میانگین معمولی بود. این به این معنیه که به جای اینکه برای یک محصول جمع امتیازها رو تقسیم بر تعداد اونا کنم، امتیازهای هر ساعت رو میانگین گرفتم و از میانگین‌های حاصل مجدد میانگین‌کلی گرفتم. البته اینکه من بازه‌ها رو هر ساعت درنظر گرفتم شاید بهینه‌ترین نباشه. پیدا کردن یه بازهٔ بهینه نیازمند بررسی آماری ترافیک داده‌های ورودیه.

اما چرا فکر می‌کنم این روش به شیوهٔ موثری تاثیر اسپم‌ها رو کم می‌کنه؟ اگه دقت کنیم اسپم‌هایی که مثلاً از شیر لینک محصول یا به هر طریقی مثلا توی تلگرام ایجاد می‌شند مقداری زیادی دیتا در بازهٔ زمانی کوتاه پس از شیر شدن لینک توی مسنجر یا شبکه اجتماعی سواستفاده‌گرند. پس با دستهٔ بندی زمانی امتیازدهی‌ها تاثیر‌بخشی وزنی امتیازاتی که دربازهٔ زمانی نزدیک به هم هستند کم‌تر می‌شه. 

برای روشن‌شدن بهتر عملکرد ریاضی فرض کنیم ۴ تا عدد داریم که در ۴ زمان مختلف ایجاد شدن:

| rating | time | 
| ----- | -----|
|   5  | 9:00 |
|   5  | 9:01 |
|   5  | 9:15 |
|   2  | 11:00 |

همین‌جا هم کمی پیداست که سه‌داده اول شباهت زیادی به داده‌های اسپم‌شده از یک منبع دارند. اما ریاضیات ما چطور کار می‌کنند؟

در مدل ما سه دادهٔ اول با هم و داده‌ی آخری به تنهایی میانگین گرفته می‌شوند.

یعنی:

سه‌تای اول
 `15 ÷ 3 = 5`
و دادهٔ اخر 
 `2 ÷ 1 = 2`
 حال میانگین این دو میانگین برابر است با

 `(5 + 2)/2 = 7 / 2 = 3.5`

 در حالی که به حالت معمول میانگین این چهار عدد برابر است با 

`(5 + 5 + 5 + 2) / 4 = 4.25‍`

که طبیعتاً تاثیر بیشتری از سه‌داده‌ی اول پذیرفته است. پس روش اول تا حدودی این مساله را نرمال‌سازی می‌کند.

## روش من در پیاده‌سازی در جنگو

برای پیاده‌سازی این مساله در جنگو و در سطح ORM من در سریالایزر مربوط به محصولات ابتدا کوئری‌ست امتیازهای آن محصول رو به دست آوردم:

```related_rating_qs = ProductRating.objects.filter(product=obj)```

سپس با استفاده از تابع TrunHour به شکل ساعتی کوئری رو دسته‌بندی کردم و به اصطلاح آماری سری‌زمانی داده‌ها رو ایجاد کردم


‍‍‍```hourly_rating = related_rating_qs.annotate(hour=TruncHour('timestamp'))```

سپس به ازای هر دستهٔ یک ساعته میانگین فیلد rating رو حساب کردم:

‍‍
```hourly_average_ratings = hourly_rating.values('hour').annotate(hourly_avg=Avg('rating'))```

و در انتها با استفاده از تابع میانگین روی کل میانگین‌ها داده‌ها رو تجمیع کردم.

‍‍‍```overal_rating = hourly_average_ratings.aggregate(overall_avg=Avg('hourly_avg'))```

کد مربوط در مسیر `bitpin_task/api/serializers.py` و در کلاس ‍`ProductSerializer` و متد `get_overal_rating` در دسترسه.


-----------------------


یه نکته الان که پروژه رو ارسال کردم براتون به ذهنم رسید و گفتم شاید بد نباشه اضافه کنم و احتمالا می‌تونه ترکیب شه به روش فعلی من.

احتمالاًً روش‌های مثل میانگین‌گیری وینزوری از مقاطع ساعتی بتونه کمک کنه. چون اساساً داده‌های اسپم از نوع مینیم و ماکسیمم هستن یعنی امتیازهای صفر و ۵ توی این طیف امتیازدهی. توی این روز از کوچکترین و بزرگترین داده‌ها تعدادی رو حذف می‌کنن و تا حدودی میانگین‌گری تصحیح می‌شه.


------------------------

با تشکر.